{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c75cd30b",
   "metadata": {},
   "source": [
    "# train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "314abe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import libraries\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForCausalLM, \n",
    "    TrainingArguments, \n",
    "    Trainer,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1565a411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Using model: microsoft/DialoGPT-small\n",
      "üíæ Output directory: ../models/crop_recommendation_proper\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Configuration - Use a balanced model\n",
    "MODEL_NAME = \"microsoft/DialoGPT-small\"  # 117M parameters - good balance\n",
    "DATASET_PATH = \"../data/llm_train/prompt_response_dataset.csv\"\n",
    "OUTPUT_DIR = \"../models/crop_recommendation_proper\"\n",
    "\n",
    "print(f\"üöÄ Using model: {MODEL_NAME}\")\n",
    "print(f\"üíæ Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "519ae309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Loading and analyzing dataset...\n",
      "Dataset size: 4513\n",
      "\n",
      "üîç Data sample:\n",
      "Prompt: Given that soil color is Black, nitrogen is 75, phosphorus is 50, potassium is 100, ph is 6.5, rainfall is 1000, temperature is 20, which crop should be planted?\n",
      "Response: Sugarcane\n",
      "\n",
      "Unique crops: ['Sugarcane' 'Jowar' 'Cotton' 'Rice' 'Wheat' 'Groundnut' 'Maize' 'Tur'\n",
      " 'Urad' 'Moong']\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Load and analyze data\n",
    "print(\"üìä Loading and analyzing dataset...\")\n",
    "df = pd.read_csv(DATASET_PATH)\n",
    "print(f\"Dataset size: {len(df)}\")\n",
    "\n",
    "# Check the data format\n",
    "print(\"\\nüîç Data sample:\")\n",
    "print(\"Prompt:\", df['prompt'].iloc[0])\n",
    "print(\"Response:\", df['response'].iloc[0])\n",
    "print(\"\\nUnique crops:\", df['response'].unique()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8cb17de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Creating training format...\n",
      "Sample training text:\n",
      "### Instruction:\n",
      "Given that soil color is Black, nitrogen is 75, phosphorus is 50, potassium is 100, ph is 6.5, rainfall is 1000, temperature is 20, which crop should be planted?\n",
      "\n",
      "### Response:\n",
      "Sugarcane\n",
      "--------------------------------------------------\n",
      "Train size: 4061\n",
      "Eval size: 452\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Create proper training format\n",
    "print(\"üìù Creating training format...\")\n",
    "\n",
    "# Use a clear, consistent format that matches inference\n",
    "def format_training_example(row):\n",
    "    return f\"### Instruction:\\n{row['prompt']}\\n\\n### Response:\\n{row['response']}\"\n",
    "\n",
    "training_texts = [format_training_example(row) for _, row in df.iterrows()]\n",
    "\n",
    "# Verify format\n",
    "print(\"Sample training text:\")\n",
    "print(training_texts[0])\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Create dataset\n",
    "dataset = Dataset.from_dict({\"text\": training_texts})\n",
    "\n",
    "# Split dataset\n",
    "train_test_split = dataset.train_test_split(test_size=0.1, seed=42, shuffle=True)\n",
    "train_dataset = train_test_split[\"train\"]\n",
    "eval_dataset = train_test_split[\"test\"]\n",
    "\n",
    "print(f\"Train size: {len(train_dataset)}\")\n",
    "print(f\"Eval size: {len(eval_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e712317d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Loading model and tokenizer...\n",
      "‚úÖ Model loaded: microsoft/DialoGPT-small\n",
      "üìä Model parameters: 124,439,808\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Load model and tokenizer\n",
    "print(\"üöÄ Loading model and tokenizer...\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
    "\n",
    "print(f\"‚úÖ Model loaded: {MODEL_NAME}\")\n",
    "print(f\"üìä Model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9c8eb19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Tokenizing datasets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86a7ac7af0754e04b4cfec335788f545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4061 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b2c7bb7169f46cb8681e842b3bc14da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/452 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tokenization complete\n",
      "Sample tokenized: {'input_ids': [21017, 46486, 25, 198, 15056], 'attention_mask': [1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Proper tokenization with attention masks\n",
    "def tokenize_function(examples):\n",
    "    # Tokenize with proper attention masks\n",
    "    tokenized = tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=256,\n",
    "        return_tensors=None,\n",
    "    )\n",
    "    \n",
    "    # For causal LM, labels are the same as input_ids\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
    "    return tokenized\n",
    "\n",
    "print(\"üîß Tokenizing datasets...\")\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True, batch_size=1000)\n",
    "tokenized_eval = eval_dataset.map(tokenize_function, batched=True, batch_size=1000)\n",
    "\n",
    "# Remove text column\n",
    "tokenized_train = tokenized_train.remove_columns([\"text\"])\n",
    "tokenized_eval = tokenized_eval.remove_columns([\"text\"])\n",
    "\n",
    "print(\"‚úÖ Tokenization complete\")\n",
    "print(\"Sample tokenized:\", {k: v[:5] for k, v in tokenized_train[0].items() if k in ['input_ids', 'attention_mask']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9c1ea7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è Training configuration:\n",
      "  - Epochs: 5\n",
      "  - Batch size: 2\n",
      "  - Learning rate: 5e-05\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Optimized training arguments for proper learning\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=5,                    # More epochs for proper learning\n",
    "    per_device_train_batch_size=2,         # Smaller batch for stability\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=4,         # Effective batch size = 2 * 4 = 8\n",
    "    warmup_steps=100,\n",
    "    logging_steps=50,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=200,\n",
    "    save_strategy=\"steps\", \n",
    "    save_steps=200,\n",
    "    learning_rate=5e-5,                    # Proper fine-tuning LR\n",
    "    use_cpu=True,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    report_to=[],\n",
    "    remove_unused_columns=True,\n",
    "    dataloader_drop_last=True,\n",
    "    save_total_limit=2,\n",
    "    prediction_loss_only=True,             # Only compute loss for speed\n",
    ")\n",
    "\n",
    "print(\"‚öôÔ∏è Training configuration:\")\n",
    "print(f\"  - Epochs: {training_args.num_train_epochs}\")\n",
    "print(f\"  - Batch size: {training_args.per_device_train_batch_size}\")\n",
    "print(f\"  - Learning rate: {training_args.learning_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "53160b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Trainer ready!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vm/pcd9by995rdf6xx5vvv6k_4h0000gn/T/ipykernel_66860/2872606684.py:7: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Data collator and trainer\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_eval,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Trainer ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2fade342",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 50256}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Starting proper training...\n",
      "‚è±Ô∏è  Estimated training time: 20-40 minutes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2540' max='2540' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2540/2540 2:30:54, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.382400</td>\n",
       "      <td>0.341853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.330100</td>\n",
       "      <td>0.308587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.308400</td>\n",
       "      <td>0.289085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.291700</td>\n",
       "      <td>0.274956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.285900</td>\n",
       "      <td>0.268073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.274900</td>\n",
       "      <td>0.258916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.269600</td>\n",
       "      <td>0.257243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.253247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.258000</td>\n",
       "      <td>0.245210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.254700</td>\n",
       "      <td>0.241934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.249200</td>\n",
       "      <td>0.239555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.247700</td>\n",
       "      <td>0.235446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training completed!\n",
      "üíæ Model saved to: ../models/crop_recommendation_proper\n",
      "üìà Final training loss: 0.4404\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Train with progress monitoring\n",
    "print(\"üéØ Starting proper training...\")\n",
    "print(\"‚è±Ô∏è  Estimated training time: 20-40 minutes\")\n",
    "\n",
    "try:\n",
    "    # Train the model\n",
    "    train_result = trainer.train()\n",
    "    \n",
    "    # Save the final model\n",
    "    trainer.save_model()\n",
    "    tokenizer.save_pretrained(OUTPUT_DIR)\n",
    "    \n",
    "    print(f\"‚úÖ Training completed!\")\n",
    "    print(f\"üíæ Model saved to: {OUTPUT_DIR}\")\n",
    "    print(f\"üìà Final training loss: {train_result.metrics['train_loss']:.4f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Training failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6476dd18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
